

# GPU, batch size, epoch c·ªë ƒë·ªãnh
# GPU=2
# BATCH=4
# EPOCH=100

# # 5 learning rate kh√°c nhau
# for LR in 5e-4 3e-4 5e-3 1e-4 2e-4
# do
#     for st in 0 
#     do
#         echo "üîπ Running with lr=$LR, stu-type=$st ..."
#         python main_overlap_tag2.py \
#             --gpu $GPU \
#             --batch-size $BATCH \
#             --num-epochs $EPOCH \
#             --lr $LR \
#             --stu-type $st
#     done
# done
# CUDA_VISIBLE_DEVICES=1 python main_overlap_tag.py --gpu 0 --batch-size 4 --num-epochs 100 --lr 1e-3 --stu-type 0  \
# & CUDA_VISIBLE1DEVICES=0 python main_overlap_tag.py --gpu 0 --batch-size 4 --num-epochs 100 --lr 1e-2 --stu-type 0 \
# & CUDA_VISIBLE_DEVICES=2 python main_overlap_tag.py --gpu 0 --batch-size 64 --num-epochs 100 --lr 1e-2 --stu-type 0
# CUDA_VISIBLE_DEVICES=0 python main_overlap_tag.py --gpu 0 --batch-size 4 --num-epochs 100 --lr 5e-4 --stu-type 0
#  CUDA_VISIBLE_DEVICES=1 python main_overlap_tag.py --gpu 0 --batch-size 4 --num-epochs 100 --lr 1e-2 --stu-type 0


CUDA_VISIBLE_DEVICES=0 python main_overlap_tag.py --gpu 0 --batch-size 64 --num-epochs 200 --lr 3e-4 --stu-type 0 --distill_type 2 &

# ƒê·ª£i 1 ph√∫t (60 gi√¢y) r·ªìi ch·∫°y job 2
sleep 60
CUDA_VISIBLE_DEVICES=1 python main_overlap_tag.py --gpu 0 --batch-size 64 --num-epochs 200 --lr 3e-4 --stu-type 0 --distill_type 21 &

# ƒê·ª£i th√™m 1 ph√∫t n·ªØa r·ªìi ch·∫°y job 3
sleep 60
CUDA_VISIBLE_DEVICES=2 python main_overlap_tag.py --gpu 0 --batch-size 64 --num-epochs 200 --lr 3e-4 --stu-type 0 --distill_type 22 &